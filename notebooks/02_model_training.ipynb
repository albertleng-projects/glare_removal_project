{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3135ea1d-7ac0-402d-b056-3248d94833f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: pytorch-msssim in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\albert.leng\\pycharmprojects\\glare_removal_project\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [1:37:59<00:00,  7.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 0.2343\n",
      "Epoch 1 - Validation Loss: 0.1971\n",
      "âœ… Best Model Saved at: ..\\models\\best_glare_removal_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [1:32:40<00:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.1693\n",
      "Epoch 2 - Validation Loss: 0.1751\n",
      "âœ… Best Model Saved at: ..\\models\\best_glare_removal_model.pth\n",
      "ðŸ“Œ Checkpoint saved at: ..\\models\\glare_model_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [1:31:52<00:00,  7.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.1625\n",
      "Epoch 3 - Validation Loss: 0.1691\n",
      "âœ… Best Model Saved at: ..\\models\\best_glare_removal_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [1:40:20<00:00,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.1583\n",
      "Epoch 4 - Validation Loss: 0.1740\n",
      "ðŸ“Œ Checkpoint saved at: ..\\models\\glare_model_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [2:00:28<00:00,  9.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.1565\n",
      "Epoch 5 - Validation Loss: 0.1660\n",
      "âœ… Best Model Saved at: ..\\models\\best_glare_removal_model.pth\n",
      "ðŸŽ‰ Final Model Saved at: ..\\models\\final_glare_removal_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install tqdm torch torchvision pytorch-msssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.segmentation import (\n",
    "    deeplabv3_mobilenet_v3_large,\n",
    "    DeepLabV3_MobileNet_V3_Large_Weights\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# âœ… Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# âœ… Paths\n",
    "DATA_DIR = Path(\"../data/SD1\")\n",
    "PROCESSED_TRAIN_DIR = DATA_DIR / \"processed_train\"\n",
    "PROCESSED_VAL_DIR = DATA_DIR / \"processed_val\"\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)  # Ensure model directory exists\n",
    "\n",
    "# âœ… Dataset class\n",
    "class GlareRemovalDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, transform: transforms.Compose = None, limit: int = None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.image_pairs = []\n",
    "\n",
    "        # Pair `glare_xxx.png` with `gt_xxx.png`\n",
    "        glare_images = sorted(self.root_dir.glob(\"glare_*.png\"))\n",
    "        gt_images = sorted(self.root_dir.glob(\"gt_*.png\"))\n",
    "\n",
    "        # Ensure correct pairing\n",
    "        for glare_img in glare_images:\n",
    "            gt_img = self.root_dir / glare_img.name.replace(\"glare_\", \"gt_\")\n",
    "            if gt_img.exists():\n",
    "                self.image_pairs.append((glare_img, gt_img))\n",
    "\n",
    "        # Limit dataset size for debugging\n",
    "        if limit:\n",
    "            self.image_pairs = random.sample(self.image_pairs, min(limit, len(self.image_pairs)))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_pairs)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        glare_path, gt_path = self.image_pairs[idx]\n",
    "        glare_img = Image.open(glare_path).convert(\"RGB\")\n",
    "        gt_img = Image.open(gt_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            glare_img = self.transform(glare_img)\n",
    "            gt_img = self.transform(gt_img)\n",
    "\n",
    "        return glare_img, gt_img\n",
    "\n",
    "# âœ… Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor (values between 0-1)\n",
    "])\n",
    "\n",
    "# âœ… Data loaders (Optimized)\n",
    "train_dataset = GlareRemovalDataset(PROCESSED_TRAIN_DIR, transform=transform)\n",
    "val_dataset = GlareRemovalDataset(PROCESSED_VAL_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=16, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# âœ… Model Definition (DeepLabV3-MobileNetV3)\n",
    "class GlareRemovalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlareRemovalModel, self).__init__()\n",
    "        self.model = deeplabv3_mobilenet_v3_large(weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT)\n",
    "        self.model.classifier[4] = nn.Conv2d(256, 3, kernel_size=1)  # Modify output channels\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)['out']\n",
    "\n",
    "# âœ… Instantiate Model\n",
    "model = GlareRemovalModel().to(device)\n",
    "\n",
    "# âœ… Custom Loss (L1 + SSIM Loss)\n",
    "def custom_loss(predicted: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    l1_loss = F.l1_loss(predicted, target)\n",
    "    ssim_loss = 1 - ssim(predicted, target, data_range=1, size_average=True)\n",
    "    return l1_loss + 0.5 * ssim_loss  # Adjust SSIM weight as needed\n",
    "\n",
    "# âœ… Optimizer & Scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "# âœ… Training loop\n",
    "num_epochs = 5  # Increased for better learning\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = custom_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # âœ… Gradient Clipping to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # âœ… Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += custom_loss(outputs, targets).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # âœ… Adjust learning rate if needed\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # âœ… Save best model checkpoint\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_path = MODEL_DIR / \"best_glare_removal_model.pth\"\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"âœ… Best Model Saved at: {best_model_path}\")\n",
    "\n",
    "    # âœ… Periodic checkpoint saving\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint_path = MODEL_DIR / f\"glare_model_epoch_{epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"ðŸ“Œ Checkpoint saved at: {checkpoint_path}\")\n",
    "\n",
    "# âœ… Save final model\n",
    "final_model_path = MODEL_DIR / \"final_glare_removal_model.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"ðŸŽ‰ Final Model Saved at: {final_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370a1fa-7174-4cca-a02a-fc59f6bdc165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
